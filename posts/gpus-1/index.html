<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Developing a reasonable understanding of GPUs for ML Workloads | Umer Jamil </title>
<meta name=keywords content="MLOps,DevOps,Nvidia,GPU,Operations,GPUs,Machine Learning,Deep Learning">
<meta name=description content="This blog is intended to develop a “breadth” level understanding of GPUs, and not a “depth” level. My aim will be to build a “reasonable” understanding that will help in our hardware decision-making for managing ML/DL workloads and pipelines from the perspective of an ML/MLOps Engineer. This blog does not contain comparisons of different GPU architectures for ML workloads.
Before diving, let&rsquo;s quickly recap some key terminologies which will be used in upcoming paras.">
<meta name=author content="Umer Jamil">
<link rel=canonical href=https://umerjamil16.github.io/posts/gpus-1/>
<meta name=google-site-verification content="XYZabc">
<meta name=yandex-verification content="XYZabc">
<meta name=msvalidate.01 content="XYZabc">
<link crossorigin=anonymous href=/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://umerjamil16.github.io/%3Clink%20/%20abs%20url%3E>
<link rel=icon type=image/png sizes=16x16 href=https://umerjamil16.github.io/%3Clink%20/%20abs%20url%3E>
<link rel=icon type=image/png sizes=32x32 href=https://umerjamil16.github.io/%3Clink%20/%20abs%20url%3E>
<link rel=apple-touch-icon href=https://umerjamil16.github.io/%3Clink%20/%20abs%20url%3E>
<link rel=mask-icon href=https://umerjamil16.github.io/%3Clink%20/%20abs%20url%3E>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3GF17TX34N"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-3GF17TX34N',{anonymize_ip:!1})}</script>
<meta property="og:title" content="Developing a reasonable understanding of GPUs for ML Workloads">
<meta property="og:description" content="This blog is intended to develop a “breadth” level understanding of GPUs, and not a “depth” level. My aim will be to build a “reasonable” understanding that will help in our hardware decision-making for managing ML/DL workloads and pipelines from the perspective of an ML/MLOps Engineer. This blog does not contain comparisons of different GPU architectures for ML workloads.
Before diving, let&rsquo;s quickly recap some key terminologies which will be used in upcoming paras.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://umerjamil16.github.io/posts/gpus-1/"><meta property="og:image" content="https://umerjamil16.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts">
<meta property="og:site_name" content="Umer Jamil">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://umerjamil16.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E">
<meta name=twitter:title content="Developing a reasonable understanding of GPUs for ML Workloads">
<meta name=twitter:description content="This blog is intended to develop a “breadth” level understanding of GPUs, and not a “depth” level. My aim will be to build a “reasonable” understanding that will help in our hardware decision-making for managing ML/DL workloads and pipelines from the perspective of an ML/MLOps Engineer. This blog does not contain comparisons of different GPU architectures for ML workloads.
Before diving, let&rsquo;s quickly recap some key terminologies which will be used in upcoming paras.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://umerjamil16.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Developing a reasonable understanding of GPUs for ML Workloads","item":"https://umerjamil16.github.io/posts/gpus-1/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Developing a reasonable understanding of GPUs for ML Workloads","name":"Developing a reasonable understanding of GPUs for ML Workloads","description":"This blog is intended to develop a “breadth” level understanding of GPUs, and not a “depth” level. My aim will be to build a “reasonable” understanding that will help in our hardware decision-making for managing ML/DL workloads and pipelines from the perspective of an ML/MLOps Engineer. This blog does not contain comparisons of different GPU architectures for ML workloads.\nBefore diving, let\u0026rsquo;s quickly recap some key terminologies which will be used in upcoming paras.","keywords":["MLOps","DevOps","Nvidia","GPU","Operations","GPUs","Machine Learning","Deep Learning"],"articleBody":"This blog is intended to develop a “breadth” level understanding of GPUs, and not a “depth” level. My aim will be to build a “reasonable” understanding that will help in our hardware decision-making for managing ML/DL workloads and pipelines from the perspective of an ML/MLOps Engineer. This blog does not contain comparisons of different GPU architectures for ML workloads.\nBefore diving, let’s quickly recap some key terminologies which will be used in upcoming paras.\n   No Term Descripion     1 Latency Latency is a time delay between the moment something is initiated, and the moment one of its effects begins or becomes detectable   2 Throughput Throughput is the amount of work done in a given amount of time   3 FLOPS floating-point operations per second. Used to calculate the computing performance of the ALUs.   4 Device GPU = set of multiprocessor   5 Device memory VRAM of GPU   6 Host CPU of the host system   7 Multiprocessor set of processors \u0026 shared memory   8 Kernel GPU program (do not confuse it with Linux kernel)   11 SIMD Single Instruction, Multiple Data (SIMD) units refer to hardware components that perform the same operation on multiple data operands concurrently. Used in GPUs   12 GP-GPUs General Purpose Graphics Processing Units   13 CUDA Compute Unified Device Architecture. A parallel computing platform and programming model for general computing on graphical processing units (GPUs)   14 ALUs Arithmetic Logic Units. Part of a central processing unit that carries out arithmetic and logic operations on the operands in computer instruction words.   15 Cache A cache is a smaller, faster memory, located closer to a processor core, which stores copies of the data from frequently used main memory locations.   16 Registers They hold a small amount of data, computer instructions or the storage address of any particular information   17 Clock Speed The number of cycles that the processor executes per second.    What is a GPU The GPUs architecture, in the beginning, was highly tuned for performing graphics pipeline operations and rendering real-time graphics. Today, their fame is not due to their ability to render 3D graphics but because of their massive computing power. GPUs have evolved from domain-specific hardware (graphics rendering) to highly efficient general-purpose high-compute capability hardware.\nThe initial GPUs had a very fixed function, performing different pipeline stages such as follows: A simplified architecture of early GPU is as follows: For each fixed function the GPUs were supposed to perform, dedicated API calls existed and were implemented in hardware. For using these GPUs for computational workloads, all tasks have to be mapped to the computer graphics domain. For early GPUs intended for graphics operations, the programmer needed to write the program using a graphics language such as OpenGL. This approach was not scalable to problem domains that do not map well to computer graphics. This leads to the design of general-purpose GPU architectures and corresponding programming models such as (CUDA, CAL, and OpenCL).\nKey Difference of GPU and GP-GPU    No GPU GP-GPU     1. Fixed functions Programmable processor   2. Early GPUs were focused on integer arithmetic, not for floating point operations Floating point arithmetic   3. No instruction set or memory Instruction set and memory for high throughput    Modern-day GP-GPU have high FLOPS (NVIDIA A100 delivers 312 teraFLOPS (TFLOPS)) and programmability.\nHardware Components To understand the hardware components of GPUs, we need to understand the hardware components of the CPU first.\nCPU Hardware Let’s consider a very simple architecture for CPU:\nIt has the following components:\n   No Component Purpose     1. ALU Performs the arithmetic and logical functions   2. Registers Used to store data during/after the operation, facilitate data movement   3. Control Units Decides which instruction to execute and then which data to pick up and send to ALU for execution   4 Cache The CPU never reads data from RAM. They use layers of Cache (L1, L2, etc). The reason is cache memory is faster than system RAM and closer to the CPU because it is on a processing chip.Predictive algorithms are used to move data from RAM into the cache. There exist a cache hierarchy (L1, L2, L3 cache) L3, L2 designed to predict what data and program instruction will be needed next, move that data from RAM and move it closer to the CPU to be ready when required. L1 is Closet to CPU and ​​used for storing the microprocessor’s recently accessed information.   5 RAM A temporary storage bank used to store data so that it can be retrieved quickly.    Process of running a program on a multicore CPU The steps are as follows:\n Operating System (OS) loads the program into RAM OS selects CPU execution context OS interrupts the processor Prepares execution context (sets contents of registers, program counter, etc. to prepare execution context) Start trigger The processor starts executing instructions  Now we understand what is a CPU and how it works, let us dive into the difference between CPU and GPU\nGPU Hardware A cartoon diagram of Nvidai GPU is shown below: The three main components of GPUs are:\n  ALUs (steam multiprocessor in case of Nvidia)\n ALUs are the smallest unit of processing. Instead, we will talk about it in terms of cores. Each core can have multiple ALUs. For example, each CUDA core includes 32 ALUs. There are 6912 CUDA cores in A100. (More than six thousand!) NVIDIA also has introduced Tensor cores in the latest Ampere architecture. Tensor cores are more suitable for Deep Learning workloads which are essentially large dimensions matrix multiplications. Quick difference between CUDA and Tensor Cores: CUDA cores perform one operation per clock cycle, whereas tensor cores can perform multiple operations per clock cycle. Tensor Cores are so fast that computation is no longer a bottleneck. The only bottleneck is getting data to the Tensor Cores (Memory Bandwidth). So for DL workloads, it is preferable to get NVIDIA GPU with Tensor Cores.    Memory bandwidth\n This is often the overlooked metric when it comes to GPUs. Memory bandwidth is defined as how fast data from/to memory (VRAM) can be moved to computation cores. So if GPU memory bandwidth is not good, but its computation cores are good, the computation cores will be unutilized most of the time because of slower data travel speed. We know that tensor cores have a high number of TFLOPS. However, during training of the BERT Large model, we have tensor core TFLOPS utilization of about 30% which means that tensor cores are sitting idle for 70% of the time just because there is a delay in the availability of data. We can say that GPU memory bandwidth is the single best indicator for each GPU’s performance is their memory bandwidth. For example, The A100 GPU has 1,555 GB/s memory bandwidth vs the 900 GB/s of the V100. As such, a basic estimate of the speedup of an A100 vs V100 is 1555/900 = 1.73x. Overcoming bandwidth limits are a common challenge for GPU compute application developers.    Shared Memory / L1 Cache Size / Registers\n Since memory bandwidth is a limiting factor in GPU performance, memory hierarchy is used to enable faster data transfer to Tensor cores. Overall, we can see that the Ampere architecture is optimized to make the available memory bandwidth more effective by using an improved memory hierarchy: from global memory to shared memory tiles, to register tiles for Tensor Cores. A generic diagram of GPU memory hierarchy is as follows  We can see that the bandwidth amplifies as we move to left side, to the computing cores. Cache hierarchy reduces throughput demand on main memory    Process of running a program on a GPU Prior 2007 (GPU) Task: Drawing a picture using a GPU\n Application (via graphics driver) provides GPU vertex and fragment shader program binaries Application sets graphics pipeline parameters (e.g., output image size) Application provides hardware a buffer of vertices drawPrimitives(vertex_buffer)  Early GPU hardware could only execute graphics pipeline computations.\nAfter 2007 (GP-GPU) Task: running a computational workload (non-graphic) on GPU\n Application allocates buffers in GPU memory Copy data to/from buffers Application (via graphics driver) provides GPU a single kernel program binary Application tells GPU to run the kernel in an SPMD fashion (“run N instances”) launch(myKernel, N)  Comparison: CPU vs GPU Now we know about CPU and GPU hardware components. Let us do a quick comparison for both.\nFor CPU:  ALUs  Less (at max 40 cores) CPU cores are more complex (have more instructions) and thus larger than GPU cores They handle a variety of tasks.   Control Units (CU)  Large number of CU Runs a large number of multiple tasks such as OS, App1, App2, etc   Cache  Large cache (in MBs) Helps the CPU core to access data at a higher speed and hence increase the execution speed The processor core can access what is in cache in a few clock cycles. If what it needs is not there, it takes about 100 cycles to get it from memory. Latency is optimized via large caches CPUs are designed to maximize running operations out of cache, therefore they need large cache   Clock Speed  High clock speed (GHz) Because the CPU is designed to handle a variety of tasks The computations on the CPU are single-threaded, so to increase the single thread performance, the cloak speed is higher   RAM  Very large, in TBs A temporary storage bank used to store data so that it can be retrieved quickly We can open many programs, etc.    For GPU:  ALUs  Large (6912 tensor cores for A100) GPUs perform the same operation on multiple data items in parallel. Result: GPU can process vast amounts of data in a single workload. Compute units are based on SIMD hardware.   Control Units  Small number of CU In GPU, we often have to perform similar tasks (computing matrix or modeling complex numbers e.g.), so not a large number of CU are required   Cache  Small cache (in KBs) GPUs do not need a large cache, they can dedicate more of the transistor area to computation horsepower   Clock speed  Slower (MHz) Incase of GPU, we will be performing the same set of operation on data repeatedly, because not a variety of tasks are required   VRAM, video memory, device memory  In GBs Used to exchange data between CPU and GPU It is allocated and managed by the host (CPU) Accessible to both host and GPU It is significantly larger than the L1, L2 cache registers High bandwidth should be considered for VRAM    Quick summary: GPU vs CPU Let’s do a quick summary comparison.\n    CPU GPU     Strengths Very large main memory (RAM) High bandwidth main memory    Very fast clock speed More compute resources (Cores)    Latency optimized via large caches High throughput   Weakness Relatively low memory bandwidth     Cache misses very costly Relatively low memory capacity   Low performance/ watt Low per thread performance each core runs at ~1 Ghz i.e. 4 times slower than CPU core     In short:\n CPUs are low latency low throughput processors GPUs are high latency high throughput processors CPUs use task parallelism (Multiple tasks map to multiple threads) GPUs use data parallelism (Same instruction on different data)  Which GPUs to choose for Deep Learning? I will cover this question in another detailed post, right now lets discuss briefly the facotrs to consider when choosing GPUs for ML Workloads. These factors are as follows:\n Tensor cores (explained previously) Memory bandwidth  If we take the Tesla A100 GPU bandwidth vs Tesla V100 bandwidth, we get a speedup of 1555/900 = 1.73x   Shared memory size  For example, We have the following shared memory sizes on the following architectures: Volta: 96kb shared memory / 32 kb L1 Turing: 64kb shared memory / 32 kb L1 Ampere: 164 kb shared memory / 32 kb L1    Summary In this post, we dived in a breadth and depth manner to develop a reasonable understanding of GPUs. We develop familiarity with GPU/CPU hardware, their key differences, and what technical specifications to look for when buying GPUs. We also briefly discussed how to choose a GPU for Deep Learning. I will cover more on it in a systematic manner in my next posts.\nReferences  https://download.nvidia.com/developer/cuda/seminar/TDCI_Arch.pdf https://www.cs.cmu.edu/afs/cs/academic/class/15418-s18/www/lectures/06_gpuarch.pd http://haifux.org/lectures/267/Introduction-to-GPUs.pdf https://ec.europa.eu/programmes/erasmus-plus/project-result-content/52dfac24-28e9-4379-8f28-f8ed05e225e0/lec03_gpu_architectures.pdf https://download.nvidia.com/developer/cuda/seminar/TDCI_Arch.pdf https://hdms.bsz-bw.de/frontdoor/deliver/index/docId/4500/file/gpgpu-origins-and-gpu-hardware-architecture.pdf https://www.cs.cmu.edu/afs/cs/academic/class/15418-s18/www/lectures/06_gpuarch.pdf http://www.irisa.fr/alf/downloads/collange/cours/ada2020_gpu_1.pdf https://homes.luddy.indiana.edu/achauhan/Teaching/B649/2011-Fall/StudentPresns/gpu-arch.pdf http://www.ziti.uni-heidelberg.de/ziti/uploads/ce_group/seminar/2014-Daniel_Schlegel-presentation.pdf https://www.control.lth.se/fileadmin/control/Education/DoctorateProgram/DeepLearning/2016/presentation.pdf https://www.nvidia.co.uk/docs/IO/147844/Deep-Learning-With-GPUs-MaximMilakov-NVIDIA.pdf https://repository.library.northeastern.edu/files/neu:m046sc381/fulltext.pdf https://www.comp.nus.edu.sg/~cs2100/2_resources/AppendixA_Graphics_and_Computing_GPUs.pdf http://www.compsci.hunter.cuny.edu/~sweiss/course_materials/csci360/lecture_notes/gpus.pdf https://www.cs.wm.edu/~kemper/cs654/slides/nvidia.pdf http://passlab.github.io/CSE436536/notes/lecture19_GPUArchCUDA01.pdf https://www.cs.utah.edu/~jeffp/teaching/MCMD/S20-GPU.pdf http://courses.cms.caltech.edu/cs101gpu/Old/2015_lectures/cs179_2015_lec05.pdf http://haifux.org/lectures/267/Introduction-to-GPUs.pdf https://www.nvidia.com/en-us/geforce/graphics-cards/compare/ https://blog.paperspace.com/gpu-memory-bandwidth/ https://www.cs.cmu.edu/afs/cs/academic/class/15418-s18/www/lectures/06_gpuarch.pdf  ","wordCount":"2020","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","author":{"@type":"Person","name":"Umer Jamil"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://umerjamil16.github.io/posts/gpus-1/"},"publisher":{"@type":"Organization","name":"Umer Jamil ","logo":{"@type":"ImageObject","url":"https://umerjamil16.github.io/%3Clink%20/%20abs%20url%3E"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://umerjamil16.github.io/ accesskey=h title="Home (Alt + H)">
<img src=https://umerjamil16.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a>
<div class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</div>
</div>
<ul id=menu>
<li>
<a href=https://umerjamil16.github.io/categories/ title=categories>
<span>categories</span>
</a>
</li>
<li>
<a href=https://umerjamil16.github.io/tags/ title=tags>
<span>tags</span>
</a>
</li>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<div class=breadcrumbs><a href=https://umerjamil16.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://umerjamil16.github.io/posts/>Posts</a></div>
<h1 class=post-title>
Developing a reasonable understanding of GPUs for ML Workloads
</h1>
<div class=post-meta>10 min&nbsp;·&nbsp;2020 words&nbsp;·&nbsp;Umer Jamil&nbsp;|&nbsp;<a href=#/posts/gpus-1.md rel="noopener noreferrer" target=_blank>Suggest Changes (Disabled)</a>
</div>
</header>
<div class=post-content><p>This blog is intended to develop a “breadth” level understanding of GPUs, and not a “depth” level. My aim will be to build a “reasonable” understanding that will help in our hardware decision-making for managing ML/DL workloads and pipelines from the perspective of an ML/MLOps Engineer. This blog does not contain comparisons of different GPU architectures for ML workloads.</p>
<p>Before diving, let&rsquo;s quickly recap some key terminologies which will be used in upcoming paras.</p>
<table>
<thead>
<tr>
<th>No</th>
<th>Term</th>
<th>Descripion</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Latency</td>
<td>Latency is a time delay between the moment something is initiated, and the moment one of its effects begins or becomes detectable</td>
</tr>
<tr>
<td>2</td>
<td>Throughput</td>
<td>Throughput is the amount of work done in a given amount of time</td>
</tr>
<tr>
<td>3</td>
<td>FLOPS</td>
<td>floating-point operations per second. Used to calculate the computing performance of the ALUs.</td>
</tr>
<tr>
<td>4</td>
<td>Device</td>
<td>GPU = set of multiprocessor</td>
</tr>
<tr>
<td>5</td>
<td>Device memory</td>
<td>VRAM of GPU</td>
</tr>
<tr>
<td>6</td>
<td>Host</td>
<td>CPU of the host system</td>
</tr>
<tr>
<td>7</td>
<td>Multiprocessor</td>
<td>set of processors & shared memory</td>
</tr>
<tr>
<td>8</td>
<td>Kernel</td>
<td>GPU program (do not confuse it with Linux kernel)</td>
</tr>
<tr>
<td>11</td>
<td>SIMD</td>
<td>Single Instruction, Multiple Data (SIMD) units refer to hardware components that perform the same operation on multiple data operands concurrently. Used in GPUs</td>
</tr>
<tr>
<td>12</td>
<td>GP-GPUs</td>
<td>General Purpose Graphics Processing Units</td>
</tr>
<tr>
<td>13</td>
<td>CUDA</td>
<td>Compute Unified Device Architecture. A parallel computing platform and programming model for general computing on graphical processing units (GPUs)</td>
</tr>
<tr>
<td>14</td>
<td>ALUs</td>
<td>Arithmetic Logic Units. Part of a central processing unit that carries out arithmetic and logic operations on the operands in computer instruction words.</td>
</tr>
<tr>
<td>15</td>
<td>Cache</td>
<td>A cache is a smaller, faster memory, located closer to a processor core, which stores copies of the data from frequently used main memory locations.</td>
</tr>
<tr>
<td>16</td>
<td>Registers</td>
<td>They hold a small amount of data, computer instructions or the storage address of any particular information</td>
</tr>
<tr>
<td>17</td>
<td>Clock Speed</td>
<td>The number of cycles that the processor executes per second.</td>
</tr>
</tbody>
</table>
<h2 id=what-is-a-gpu>What is a GPU<a hidden class=anchor aria-hidden=true href=#what-is-a-gpu>#</a></h2>
<p>The GPUs architecture, in the beginning, was highly tuned for performing graphics pipeline operations and rendering real-time graphics. Today, their fame is not due to their ability to render 3D graphics but because of their massive computing power. GPUs have evolved from domain-specific hardware (graphics rendering) to highly efficient general-purpose high-compute capability hardware.</p>
<p>The initial GPUs had a very fixed function, performing different pipeline stages such as follows:
<img loading=lazy src=https://i.postimg.cc/zv30c7yQ/gpu1.png alt="GPU Architecture">
</p>
<p>A simplified architecture of early GPU is as follows:
<img loading=lazy src=https://i.postimg.cc/RCjDYrTQ/gpu2.png alt="GPU Architecture">
</p>
<p>For each fixed function the GPUs were supposed to perform, dedicated API calls existed and were implemented in hardware. For using these GPUs for computational workloads, all tasks have to be mapped to the computer graphics domain. For early GPUs intended for graphics operations, the programmer needed to write the program using a graphics language such as OpenGL. This approach was not scalable to problem domains that do not map well to computer graphics. This leads to the design of general-purpose GPU architectures and corresponding programming models such as (CUDA, CAL, and OpenCL).</p>
<h3 id=key-difference-of-gpu-and-gp-gpu>Key Difference of GPU and GP-GPU<a hidden class=anchor aria-hidden=true href=#key-difference-of-gpu-and-gp-gpu>#</a></h3>
<table>
<thead>
<tr>
<th>No</th>
<th>GPU</th>
<th>GP-GPU</th>
</tr>
</thead>
<tbody>
<tr>
<td>1.</td>
<td>Fixed functions</td>
<td>Programmable processor</td>
</tr>
<tr>
<td>2.</td>
<td>Early GPUs were focused on integer arithmetic, not for floating point operations</td>
<td>Floating point arithmetic</td>
</tr>
<tr>
<td>3.</td>
<td>No instruction set or memory</td>
<td>Instruction set and memory for high throughput</td>
</tr>
</tbody>
</table>
<p>Modern-day GP-GPU have high FLOPS (NVIDIA A100 delivers 312 teraFLOPS (TFLOPS)) and programmability.</p>
<h2 id=hardware-components>Hardware Components<a hidden class=anchor aria-hidden=true href=#hardware-components>#</a></h2>
<p>To understand the hardware components of GPUs, we need to understand the hardware components of the CPU first.</p>
<h3 id=cpu-hardware>CPU Hardware<a hidden class=anchor aria-hidden=true href=#cpu-hardware>#</a></h3>
<p>Let&rsquo;s consider a very simple architecture for CPU:</p>
<p><img loading=lazy src=https://i.postimg.cc/tCJFF76B/1-sh8h-Dj-O4x0-S0-Q-JGx-GTKc-Q.png alt="CPU Architecture">
</p>
<p>It has the following components:</p>
<table>
<thead>
<tr>
<th>No</th>
<th>Component</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr>
<td>1.</td>
<td>ALU</td>
<td>Performs the arithmetic and logical functions</td>
</tr>
<tr>
<td>2.</td>
<td>Registers</td>
<td>Used to store data during/after the operation, facilitate data movement</td>
</tr>
<tr>
<td>3.</td>
<td>Control Units</td>
<td>Decides which instruction to execute and then which data to pick up and send to ALU for execution</td>
</tr>
<tr>
<td>4</td>
<td>Cache</td>
<td>The CPU never reads data from RAM. They use layers of Cache (L1, L2, etc). The reason is cache memory is faster than system RAM and closer to the CPU because it is on a processing chip.Predictive algorithms are used to move data from RAM into the cache. There exist a cache hierarchy (L1, L2, L3 cache) L3, L2 designed to predict what data and program instruction will be needed next, move that data from RAM and move it closer to the CPU to be ready when required. L1 is Closet to CPU and ​​used for storing the microprocessor&rsquo;s recently accessed information.</td>
</tr>
<tr>
<td>5</td>
<td>RAM</td>
<td>A temporary storage bank used to store data so that it can be retrieved quickly.</td>
</tr>
</tbody>
</table>
<h4 id=process-of-running-a-program-on-a-multicore-cpu>Process of running a program on a multicore CPU<a hidden class=anchor aria-hidden=true href=#process-of-running-a-program-on-a-multicore-cpu>#</a></h4>
<p>The steps are as follows:</p>
<ul>
<li>Operating System (OS) loads the program into RAM</li>
<li>OS selects CPU execution context OS interrupts the processor</li>
<li>Prepares execution context (sets contents of registers, program counter, etc. to prepare
execution context)</li>
<li>Start trigger The processor starts executing instructions</li>
</ul>
<p>Now we understand what is a CPU and how it works, let us dive into the difference between CPU and GPU</p>
<h3 id=gpu-hardware>GPU Hardware<a hidden class=anchor aria-hidden=true href=#gpu-hardware>#</a></h3>
<p>A cartoon diagram of Nvidai GPU is shown below:
<img loading=lazy src=https://i.postimg.cc/PfRCsyLM/gpu3.png alt="GPU nvidia architecture">
</p>
<p>The three main components of GPUs are:</p>
<ol>
<li>
<p>ALUs (steam multiprocessor in case of Nvidia)</p>
<ul>
<li>ALUs are the smallest unit of processing. Instead, we will talk about
it in terms of cores. Each core can have multiple ALUs.</li>
<li>For example, each CUDA core includes 32 ALUs. There are 6912 CUDA cores in A100.
(More than six thousand!) NVIDIA also has introduced Tensor cores in
the latest Ampere architecture.</li>
<li>Tensor cores are more suitable for Deep Learning workloads which are essentially large dimensions matrix multiplications.</li>
<li>Quick difference between CUDA and Tensor Cores:
CUDA cores perform one operation per clock cycle, whereas tensor
cores can perform multiple operations per clock cycle.</li>
<li>Tensor Cores are so fast that computation is no longer a bottleneck. The only
bottleneck is getting data to the Tensor Cores (Memory Bandwidth).</li>
<li>So for DL workloads, it is preferable to get NVIDIA GPU with Tensor Cores.</li>
</ul>
</li>
<li>
<p>Memory bandwidth</p>
<ul>
<li>This is often the overlooked metric when it comes to GPUs.</li>
<li>Memory bandwidth is defined as how fast data from/to memory (VRAM) can be moved to computation cores.</li>
<li>So if GPU memory bandwidth is not good, but its computation cores are good, the computation cores will be unutilized most of the time because of slower data travel speed.</li>
<li>We know that tensor cores have a high number of TFLOPS. However, during training of the BERT Large model, we have tensor core TFLOPS utilization of about 30% which means that tensor cores are sitting idle for 70% of the time just because there is a delay in the availability of data.</li>
<li>We can say that GPU memory bandwidth is the single best indicator for each GPU’s performance is their memory bandwidth. For example, The A100 GPU has 1,555 GB/s memory bandwidth vs the 900 GB/s of the V100. As such, a basic estimate of the speedup of an A100 vs V100 is 1555/900 = 1.73x.</li>
<li>Overcoming bandwidth limits are a common challenge for GPU compute application developers.</li>
</ul>
</li>
<li>
<p>Shared Memory / L1 Cache Size / Registers</p>
<ul>
<li>Since memory bandwidth is a limiting factor in GPU performance, memory hierarchy is used to enable faster data transfer to Tensor cores.</li>
<li>Overall, we can see that the Ampere architecture is optimized to make the available memory bandwidth more effective by using an improved memory hierarchy: from global memory to shared memory tiles, to register tiles for Tensor Cores.</li>
<li>A generic diagram of GPU memory hierarchy is as follows
<img loading=lazy src=https://i.postimg.cc/BZgdX75x/gpu4.png alt="GPU Memory Hierarchy">
</li>
<li>We can see that the bandwidth amplifies as we move to left side, to the computing cores. Cache hierarchy reduces throughput demand on main memory</li>
</ul>
</li>
</ol>
<h4 id=process-of-running-a-program-on-a-gpu>Process of running a program on a GPU<a hidden class=anchor aria-hidden=true href=#process-of-running-a-program-on-a-gpu>#</a></h4>
<h5 id=prior-2007-gpu>Prior 2007 (GPU)<a hidden class=anchor aria-hidden=true href=#prior-2007-gpu>#</a></h5>
<p>Task: Drawing a picture using a GPU</p>
<ol>
<li>Application (via graphics driver) provides GPU vertex and fragment shader program binaries</li>
<li>Application sets graphics pipeline parameters (e.g., output image
size)</li>
<li>Application provides hardware a buffer of vertices</li>
<li>drawPrimitives(vertex_buffer)</li>
</ol>
<p>Early GPU hardware could only execute graphics pipeline computations.</p>
<h5 id=after-2007-gp-gpu>After 2007 (GP-GPU)<a hidden class=anchor aria-hidden=true href=#after-2007-gp-gpu>#</a></h5>
<p>Task: running a computational workload (non-graphic) on GPU</p>
<ol>
<li>Application allocates buffers in GPU memory</li>
<li>Copy data to/from buffers</li>
<li>Application (via graphics driver) provides GPU a single kernel program binary</li>
<li>Application tells GPU to run the kernel in an SPMD fashion (“run N instances”)</li>
<li>launch(myKernel, N)</li>
</ol>
<h2 id=comparison-cpu-vs-gpu>Comparison: CPU vs GPU<a hidden class=anchor aria-hidden=true href=#comparison-cpu-vs-gpu>#</a></h2>
<p>Now we know about CPU and GPU hardware components. Let us do a quick comparison for both.</p>
<h3 id=for-cpu>For CPU:<a hidden class=anchor aria-hidden=true href=#for-cpu>#</a></h3>
<ol>
<li>ALUs
<ul>
<li>Less (at max 40 cores) CPU cores are more complex (have more
instructions) and thus larger than GPU cores</li>
<li>They handle a variety of tasks.</li>
</ul>
</li>
<li>Control Units (CU)
<ul>
<li>Large number of CU</li>
<li>Runs a large number of multiple tasks such as OS, App1, App2, etc</li>
</ul>
</li>
<li>Cache
<ul>
<li>Large cache (in MBs)</li>
<li>Helps the CPU core to access data at a higher speed and hence increase the execution speed</li>
<li>The processor core can access what is in cache in a few clock cycles. If what it needs is not there, it takes about 100 cycles to get it from memory.</li>
<li>Latency is optimized via large caches</li>
<li>CPUs are designed to maximize running operations out of cache, therefore they need large cache</li>
</ul>
</li>
<li>Clock Speed
<ul>
<li>High clock speed (GHz)</li>
<li>Because the CPU is designed to handle a variety of tasks</li>
<li>The computations on the CPU are single-threaded, so to increase the single thread performance, the cloak speed is higher</li>
</ul>
</li>
<li>RAM
<ul>
<li>Very large, in TBs</li>
<li>A temporary storage bank used to store data so that it can be retrieved quickly</li>
<li>We can open many programs, etc.</li>
</ul>
</li>
</ol>
<h3 id=for-gpu>For GPU:<a hidden class=anchor aria-hidden=true href=#for-gpu>#</a></h3>
<ol>
<li>ALUs
<ul>
<li>Large (6912 tensor cores for A100)</li>
<li>GPUs perform the same operation on multiple data items in parallel.</li>
<li>Result: GPU can process vast amounts of data in a single workload.</li>
<li>Compute units are based on SIMD hardware.</li>
</ul>
</li>
<li>Control Units
<ul>
<li>Small number of CU</li>
<li>In GPU, we often have to perform similar tasks (computing matrix or modeling complex numbers e.g.), so not a large number of CU are required</li>
</ul>
</li>
<li>Cache
<ul>
<li>Small cache (in KBs)</li>
<li>GPUs do not need a large cache, they can dedicate more of the transistor area to computation horsepower</li>
</ul>
</li>
<li>Clock speed
<ul>
<li>Slower (MHz)</li>
<li>Incase of GPU, we will be performing the same set of operation on data repeatedly, because not a variety of tasks are required</li>
</ul>
</li>
<li>VRAM, video memory, device memory
<ul>
<li>In GBs</li>
<li>Used to exchange data between CPU and GPU</li>
<li>It is allocated and managed by the host (CPU)</li>
<li>Accessible to both host and GPU</li>
<li>It is significantly larger than the L1, L2 cache registers</li>
<li>High bandwidth should be considered for VRAM</li>
</ul>
</li>
</ol>
<h3 id=quick-summary-gpu-vs-cpu>Quick summary: GPU vs CPU<a hidden class=anchor aria-hidden=true href=#quick-summary-gpu-vs-cpu>#</a></h3>
<p>Let&rsquo;s do a quick summary comparison.</p>
<table>
<thead>
<tr>
<th></th>
<th>CPU</th>
<th>GPU</th>
</tr>
</thead>
<tbody>
<tr>
<td>Strengths</td>
<td>Very large main memory (RAM)</td>
<td>High bandwidth main memory</td>
</tr>
<tr>
<td></td>
<td>Very fast clock speed</td>
<td>More compute resources (Cores)</td>
</tr>
<tr>
<td></td>
<td>Latency optimized via large caches</td>
<td>High throughput</td>
</tr>
<tr>
<td>Weakness</td>
<td>Relatively low memory bandwidth</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Cache misses very costly</td>
<td>Relatively low memory capacity</td>
</tr>
<tr>
<td>Low performance/ watt</td>
<td>Low per thread performance each core runs at ~1 Ghz i.e. 4 times slower than CPU core</td>
<td></td>
</tr>
</tbody>
</table>
<p>In short:</p>
<ul>
<li>CPUs are low latency low throughput processors</li>
<li>GPUs are high latency high throughput processors</li>
<li>CPUs use task parallelism (Multiple tasks map to multiple threads)</li>
<li>GPUs use data parallelism (Same instruction on different data)</li>
</ul>
<h2 id=which-gpus-to-choose-for-deep-learning>Which GPUs to choose for Deep Learning?<a hidden class=anchor aria-hidden=true href=#which-gpus-to-choose-for-deep-learning>#</a></h2>
<p>I will cover this question in another detailed post, right now lets discuss briefly the facotrs to consider when choosing GPUs for ML Workloads. These factors are as follows:</p>
<ol>
<li>Tensor cores (explained previously)</li>
<li>Memory bandwidth
<ul>
<li>If we take the Tesla A100 GPU bandwidth vs Tesla V100 bandwidth, we get a speedup of 1555/900 = 1.73x</li>
</ul>
</li>
<li>Shared memory size
<ul>
<li>For example, We have the following shared memory sizes on the following architectures:</li>
<li>Volta: 96kb shared memory / 32 kb L1</li>
<li>Turing: 64kb shared memory / 32 kb L1</li>
<li>Ampere: 164 kb shared memory / 32 kb L1</li>
</ul>
</li>
</ol>
<h2 id=summary>Summary<a hidden class=anchor aria-hidden=true href=#summary>#</a></h2>
<p>In this post, we dived in a breadth and depth manner to develop a reasonable understanding of GPUs. We develop familiarity with GPU/CPU hardware, their key differences, and what technical specifications to look for when buying GPUs. We also briefly discussed how to choose a GPU for Deep Learning. I will cover more on it in a systematic manner in my next posts.</p>
<h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2>
<ol>
<li><a href=https://download.nvidia.com/developer/cuda/seminar/TDCI_Arch.pdf>https://download.nvidia.com/developer/cuda/seminar/TDCI_Arch.pdf</a></li>
<li><a href=https://www.cs.cmu.edu/afs/cs/academic/class/15418-s18/www/lectures/06_gpuarch.pdf>https://www.cs.cmu.edu/afs/cs/academic/class/15418-s18/www/lectures/06_gpuarch.pd</a></li>
<li><a href=http://haifux.org/lectures/267/Introduction-to-GPUs.pdf>http://haifux.org/lectures/267/Introduction-to-GPUs.pdf</a></li>
<li><a href=https://ec.europa.eu/programmes/erasmus-plus/project-result-content/52dfac24-28e9-4379-8f28-f8ed05e225e0/lec03_gpu_architectures.pdf>https://ec.europa.eu/programmes/erasmus-plus/project-result-content/52dfac24-28e9-4379-8f28-f8ed05e225e0/lec03_gpu_architectures.pdf</a></li>
<li><a href=https://download.nvidia.com/developer/cuda/seminar/TDCI_Arch.pdf>https://download.nvidia.com/developer/cuda/seminar/TDCI_Arch.pdf</a></li>
<li><a href=https://hdms.bsz-bw.de/frontdoor/deliver/index/docId/4500/file/gpgpu-origins-and-gpu-hardware-architecture.pdf>https://hdms.bsz-bw.de/frontdoor/deliver/index/docId/4500/file/gpgpu-origins-and-gpu-hardware-architecture.pdf</a></li>
<li><a href=https://www.cs.cmu.edu/afs/cs/academic/class/15418-s18/www/lectures/06_gpuarch.pdf>https://www.cs.cmu.edu/afs/cs/academic/class/15418-s18/www/lectures/06_gpuarch.pdf</a></li>
<li><a href=http://www.irisa.fr/alf/downloads/collange/cours/ada2020_gpu_1.pdf>http://www.irisa.fr/alf/downloads/collange/cours/ada2020_gpu_1.pdf</a></li>
<li><a href=https://homes.luddy.indiana.edu/achauhan/Teaching/B649/2011-Fall/StudentPresns/gpu-arch.pdf>https://homes.luddy.indiana.edu/achauhan/Teaching/B649/2011-Fall/StudentPresns/gpu-arch.pdf</a></li>
<li><a href=http://www.ziti.uni-heidelberg.de/ziti/uploads/ce_group/seminar/2014-Daniel_Schlegel-presentation.pdf>http://www.ziti.uni-heidelberg.de/ziti/uploads/ce_group/seminar/2014-Daniel_Schlegel-presentation.pdf</a></li>
<li><a href=https://www.control.lth.se/fileadmin/control/Education/DoctorateProgram/DeepLearning/2016/presentation.pdf>https://www.control.lth.se/fileadmin/control/Education/DoctorateProgram/DeepLearning/2016/presentation.pdf</a></li>
<li><a href=https://www.nvidia.co.uk/docs/IO/147844/Deep-Learning-With-GPUs-MaximMilakov-NVIDIA.pdf>https://www.nvidia.co.uk/docs/IO/147844/Deep-Learning-With-GPUs-MaximMilakov-NVIDIA.pdf</a></li>
<li><a href=https://repository.library.northeastern.edu/files/neu:m046sc381/fulltext.pdf>https://repository.library.northeastern.edu/files/neu:m046sc381/fulltext.pdf</a></li>
<li><a href=https://www.comp.nus.edu.sg/~cs2100/2_resources/AppendixA_Graphics_and_Computing_GPUs.pdf>https://www.comp.nus.edu.sg/~cs2100/2_resources/AppendixA_Graphics_and_Computing_GPUs.pdf</a></li>
<li><a href=http://www.compsci.hunter.cuny.edu/~sweiss/course_materials/csci360/lecture_notes/gpus.pdf>http://www.compsci.hunter.cuny.edu/~sweiss/course_materials/csci360/lecture_notes/gpus.pdf</a></li>
<li><a href=https://www.cs.wm.edu/~kemper/cs654/slides/nvidia.pdf>https://www.cs.wm.edu/~kemper/cs654/slides/nvidia.pdf</a></li>
<li><a href=http://passlab.github.io/CSE436536/notes/lecture19_GPUArchCUDA01.pdf>http://passlab.github.io/CSE436536/notes/lecture19_GPUArchCUDA01.pdf</a></li>
<li><a href=https://www.cs.utah.edu/~jeffp/teaching/MCMD/S20-GPU.pdf>https://www.cs.utah.edu/~jeffp/teaching/MCMD/S20-GPU.pdf</a></li>
<li><a href=http://courses.cms.caltech.edu/cs101gpu/Old/2015_lectures/cs179_2015_lec05.pdf>http://courses.cms.caltech.edu/cs101gpu/Old/2015_lectures/cs179_2015_lec05.pdf</a></li>
<li><a href=http://haifux.org/lectures/267/Introduction-to-GPUs.pdf>http://haifux.org/lectures/267/Introduction-to-GPUs.pdf</a></li>
<li><a href=https://www.nvidia.com/en-us/geforce/graphics-cards/compare/>https://www.nvidia.com/en-us/geforce/graphics-cards/compare/</a></li>
<li><a href=https://blog.paperspace.com/gpu-memory-bandwidth/>https://blog.paperspace.com/gpu-memory-bandwidth/</a></li>
<li><a href=https://www.cs.cmu.edu/afs/cs/academic/class/15418-s18/www/lectures/06_gpuarch.pdf>https://www.cs.cmu.edu/afs/cs/academic/class/15418-s18/www/lectures/06_gpuarch.pdf</a></li>
</ol>
</div>
<footer class=post-footer>
<ul class=post-tags>
<li><a href=https://umerjamil16.github.io/tags/mlops/>MLOps</a></li>
<li><a href=https://umerjamil16.github.io/tags/devops/>DevOps</a></li>
<li><a href=https://umerjamil16.github.io/tags/nvidia/>Nvidia</a></li>
<li><a href=https://umerjamil16.github.io/tags/gpu/>GPU</a></li>
<li><a href=https://umerjamil16.github.io/tags/operations/>Operations</a></li>
<li><a href=https://umerjamil16.github.io/tags/gpus/>GPUs</a></li>
<li><a href=https://umerjamil16.github.io/tags/machine-learning/>Machine Learning</a></li>
<li><a href=https://umerjamil16.github.io/tags/deep-learning/>Deep Learning</a></li>
</ul>
<nav class=paginav>
<a class=prev href=https://umerjamil16.github.io/posts/my-first-post/>
<span class=title>« Prev</span>
<br>
<span>My 1st post</span>
</a>
</nav>
<div class=share-buttons>
<a target=_blank rel="noopener noreferrer" aria-label="share Developing a reasonable understanding of GPUs for ML Workloads on twitter" href="https://twitter.com/intent/tweet/?text=Developing%20a%20reasonable%20understanding%20of%20GPUs%20for%20ML%20Workloads&url=https%3a%2f%2fumerjamil16.github.io%2fposts%2fgpus-1%2f&hashtags=MLOps%2cDevOps%2cNvidia%2cGPU%2cOperations%2cGPUs%2cMachineLearning%2cDeepLearning"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Developing a reasonable understanding of GPUs for ML Workloads on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fumerjamil16.github.io%2fposts%2fgpus-1%2f&title=Developing%20a%20reasonable%20understanding%20of%20GPUs%20for%20ML%20Workloads&summary=Developing%20a%20reasonable%20understanding%20of%20GPUs%20for%20ML%20Workloads&source=https%3a%2f%2fumerjamil16.github.io%2fposts%2fgpus-1%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Developing a reasonable understanding of GPUs for ML Workloads on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fumerjamil16.github.io%2fposts%2fgpus-1%2f&title=Developing%20a%20reasonable%20understanding%20of%20GPUs%20for%20ML%20Workloads"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Developing a reasonable understanding of GPUs for ML Workloads on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fumerjamil16.github.io%2fposts%2fgpus-1%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Developing a reasonable understanding of GPUs for ML Workloads on whatsapp" href="https://api.whatsapp.com/send?text=Developing%20a%20reasonable%20understanding%20of%20GPUs%20for%20ML%20Workloads%20-%20https%3a%2f%2fumerjamil16.github.io%2fposts%2fgpus-1%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Developing a reasonable understanding of GPUs for ML Workloads on telegram" href="https://telegram.me/share/url?text=Developing%20a%20reasonable%20understanding%20of%20GPUs%20for%20ML%20Workloads&url=https%3a%2f%2fumerjamil16.github.io%2fposts%2fgpus-1%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg>
</a>
</div>
</footer>
</article>
</main>
<footer class=footer>
<span>&copy; 2022 <a href=https://umerjamil16.github.io/>Umer Jamil </a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
</body>
</html>