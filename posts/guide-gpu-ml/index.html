<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>A Beginner's Guide to GPUs for Machine Learning Workloads | Umer Jamil </title>
<meta name=keywords content="MLOps,DevOps,Nvidia,GPU,Operations,GPUs,Machine Learning,Deep Learning,Hardware,Computer Architecture,Technical Specifications,Performance,Data Processing,Data Parallelism,Task Parallelism,Memory Bandwidth,Shared Memory,Tensor Cores,Deep Learning Workloads">
<meta name=description content="This blog aims to provide a basic understanding of GPUs for ML/MLOps Engineers, without going into extensive technical details. The focus will be on developing a broad knowledge of GPUs to aid in hardware decision-making for managing ML/DL workloads and pipelines. This blog will not include comparisons of different GPU architectures for ML workloads.
Before we begin, let&rsquo;s review some key terminologies that will be used throughout this blog:
 Latency: The time delay between the initiation of a task and the detection of its effects.">
<meta name=author content="Umer Jamil">
<link rel=canonical href=https://umerjamil16.github.io/posts/guide-gpu-ml/>
<meta name=google-site-verification content="XYZabc">
<meta name=yandex-verification content="XYZabc">
<meta name=msvalidate.01 content="XYZabc">
<link crossorigin=anonymous href=/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://umerjamil16.github.io/%3Clink%20/%20abs%20url%3E>
<link rel=icon type=image/png sizes=16x16 href=https://umerjamil16.github.io/%3Clink%20/%20abs%20url%3E>
<link rel=icon type=image/png sizes=32x32 href=https://umerjamil16.github.io/%3Clink%20/%20abs%20url%3E>
<link rel=apple-touch-icon href=https://umerjamil16.github.io/%3Clink%20/%20abs%20url%3E>
<link rel=mask-icon href=https://umerjamil16.github.io/%3Clink%20/%20abs%20url%3E>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3GF17TX34N"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-3GF17TX34N',{anonymize_ip:!1})}</script>
<meta property="og:title" content="A Beginner's Guide to GPUs for Machine Learning Workloads">
<meta property="og:description" content="This blog aims to provide a basic understanding of GPUs for ML/MLOps Engineers, without going into extensive technical details. The focus will be on developing a broad knowledge of GPUs to aid in hardware decision-making for managing ML/DL workloads and pipelines. This blog will not include comparisons of different GPU architectures for ML workloads.
Before we begin, let&rsquo;s review some key terminologies that will be used throughout this blog:
 Latency: The time delay between the initiation of a task and the detection of its effects.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://umerjamil16.github.io/posts/guide-gpu-ml/"><meta property="og:image" content="https://umerjamil16.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2022-12-26T11:00:00+05:00">
<meta property="article:modified_time" content="2022-12-26T11:00:00+05:00"><meta property="og:site_name" content="Umer Jamil">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://umerjamil16.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E">
<meta name=twitter:title content="A Beginner's Guide to GPUs for Machine Learning Workloads">
<meta name=twitter:description content="This blog aims to provide a basic understanding of GPUs for ML/MLOps Engineers, without going into extensive technical details. The focus will be on developing a broad knowledge of GPUs to aid in hardware decision-making for managing ML/DL workloads and pipelines. This blog will not include comparisons of different GPU architectures for ML workloads.
Before we begin, let&rsquo;s review some key terminologies that will be used throughout this blog:
 Latency: The time delay between the initiation of a task and the detection of its effects.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://umerjamil16.github.io/posts/"},{"@type":"ListItem","position":2,"name":"A Beginner's Guide to GPUs for Machine Learning Workloads","item":"https://umerjamil16.github.io/posts/guide-gpu-ml/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"A Beginner's Guide to GPUs for Machine Learning Workloads","name":"A Beginner\u0027s Guide to GPUs for Machine Learning Workloads","description":"This blog aims to provide a basic understanding of GPUs for ML/MLOps Engineers, without going into extensive technical details. The focus will be on developing a broad knowledge of GPUs to aid in hardware decision-making for managing ML/DL workloads and pipelines. This blog will not include comparisons of different GPU architectures for ML workloads.\nBefore we begin, let\u0026rsquo;s review some key terminologies that will be used throughout this blog:\n Latency: The time delay between the initiation of a task and the detection of its effects.","keywords":["MLOps","DevOps","Nvidia","GPU","Operations","GPUs","Machine Learning","Deep Learning","Hardware","Computer Architecture","Technical Specifications","Performance","Data Processing","Data Parallelism","Task Parallelism","Memory Bandwidth","Shared Memory","Tensor Cores","Deep Learning Workloads"],"articleBody":"This blog aims to provide a basic understanding of GPUs for ML/MLOps Engineers, without going into extensive technical details. The focus will be on developing a broad knowledge of GPUs to aid in hardware decision-making for managing ML/DL workloads and pipelines. This blog will not include comparisons of different GPU architectures for ML workloads.\nBefore we begin, let’s review some key terminologies that will be used throughout this blog:\n Latency: The time delay between the initiation of a task and the detection of its effects. Throughput: The amount of work completed within a given timeframe. FLOPS: Floating-Point Operations Per Second, used to measure the computing performance of the ALUs. Device: A GPU consisting of multiple multiprocessors. Device memory: The VRAM of a GPU. Host: The CPU of the system on which the GPU is installed. Multiprocessor: A set of processors and shared memory within a GPU. Kernel: A GPU program used to execute tasks (not to be confused with the Linux kernel). SIMD: Single Instruction, Multiple Data units, which perform the same operation on multiple data operands simultaneously and are commonly found in GPUs. GP-GPUs: General-Purpose Graphics Processing Units, which can be used for a range of tasks beyond graphics processing. CUDA: Compute Unified Device Architecture, a programming model and parallel computing platform for general computing on GPUs. ALUs: Arithmetic Logic Units, which carry out arithmetic and logic operations on the operands in computer instruction words. Cache: A smaller, faster memory located closer to a processor core that stores copies of frequently used data from main memory locations. Registers: Small amounts of data, computer instructions, or storage addresses that hold information. Clock speed: The number of cycles that the processor executes per second.  What is a GPU A GPU, or Graphics Processing Unit, was originally designed to handle specific graphics pipeline operations and real-time rendering. However, GPUs have since evolved into highly efficient general-purpose hardware with massive computing power. This has led to their increased usage in machine learning and other data-intensive applications.\nThe initial GPUs were designed with fixed functions to handle specific pipeline stages, as shown in the following diagram: A simplified architecture of early GPUs is shown below:Each fixed function the GPU performed had dedicated API calls that were implemented in hardware. To use GPUs for computational workloads, tasks had to be mapped to the computer graphics domain. Early GPUs used graphics languages like OpenGL, but this approach was not scalable for problem domains that didn’t map well to computer graphics.\nThis led to the development of general-purpose GPU (GP-GPU) architectures and corresponding programming models like CUDA, CAL, and OpenCL. Modern GP-GPUs have high FLOPS, with the NVIDIA A100 delivering up to 312 teraFLOPS. They also offer programmability, unlike early GPUs which were focused on integer arithmetic and lacked instruction sets and memory for high throughput.\nGP-GPUs are programmable processors, and they have memory and instruction sets designed to handle high throughput of floating-point arithmetic operations. They are highly parallelizable, with thousands of cores per device that are organized into multiprocessors. Each multiprocessor consists of multiple processors and shared memory. A kernel is a GPU program that is executed by a multiprocessor.\nGP-GPUs use Single Instruction, Multiple Data (SIMD) units to perform the same operation on multiple data operands concurrently. They also have caches and registers to hold frequently used data or instructions, which reduces memory latency.\nOverall, GP-GPUs have evolved from their initial purpose of handling graphics pipeline operations to become powerful hardware for data-intensive applications. Their massive computing power and programmability make them a valuable tool for ML/MLOps engineers managing ML/DL workloads and pipelines.\nHardware Components To understand the hardware components of GPUs, we need to understand the hardware components of the CPU first.\nCPU Hardware A Central Processing Unit (CPU) is the primary component of a computer system that executes instructions of a program. It has the following components:\n  Arithmetic Logic Unit (ALU): The ALU performs the arithmetic and logical functions of a CPU. It is responsible for performing calculations such as addition, subtraction, and comparison operations.\n  Registers: Registers are used to store data temporarily during and after operations. They are used to facilitate data movement between different components of the CPU.\n  Control Units: Control units are responsible for managing the execution of instructions. They decide which instruction to execute and then which data to pick up and send to the ALU for execution.\n  Cache: The CPU uses cache memory to store frequently accessed data and instructions closer to the processing unit. The cache memory is faster than the main system memory (RAM) and is designed to predict what data and program instructions will be needed next. The cache memory hierarchy includes L1, L2, and L3 caches, where L1 is closest to the CPU and is used for storing the microprocessor’s recently accessed information.\n  RAM: Random Access Memory (RAM) is a temporary storage bank used to store data so that it can be retrieved quickly. When a program is loaded into RAM, the CPU reads instructions and data from RAM and then processes them.\n  Process of running a program on a multicore CPU The process of running a program on a multicore CPU involves the operating system (OS) loading the program into RAM, selecting the CPU execution context, and preparing the execution context (i.e., setting the contents of registers, program counter, etc.) before starting the trigger to execute instructions.\nNow we understand what is a CPU and how it works, let us dive into the difference between CPU and GPU\nGPU Hardware A Graphics Processing Unit (GPU) is a specialized processor designed to handle the computational requirements of graphics and other highly parallelizable tasks. A cartoon diagram of Nvidai GPU is shown below: The three main components of GPUs are:\n  ALUs and Tensor Cores: In NVIDIA GPUs, ALUs are the smallest units of processing that are grouped into cores. For example, each CUDA core in the A100 GPU consists of 32 ALUs, and there are 6912 CUDA cores in total. Additionally, NVIDIA has introduced Tensor cores in their latest Ampere architecture, which are specialized processing units that are particularly well-suited for Deep Learning workloads involving large matrix multiplications. Tensor cores can perform multiple operations per clock cycle, which is significantly faster than the one-operation-per-clock cycle performed by CUDA cores. With Tensor cores, computation is no longer the bottleneck; instead, the primary bottleneck is the speed at which data can be transferred to and from memory (Memory Bandwidth). Therefore, for Deep Learning workloads, it is preferable to have a GPU with Tensor cores.\n  Memory Bandwidth: Memory bandwidth is an often-overlooked metric in GPUs but is critical for performance. It refers to how quickly data can be moved between the memory (VRAM) and computation cores. If a GPU has poor memory bandwidth but excellent computation cores, the computation cores will be underutilized due to slower data transfer speeds. For instance, during the training of the BERT Large model, Tensor core utilization was only around 30%, meaning that Tensor cores sat idle for 70% of the time due to data availability delays. GPU memory bandwidth is the best indicator of performance, with the A100 GPU having 1,555 GB/s memory bandwidth compared to the V100’s 900 GB/s. Thus, a basic estimate of the A100’s speedup over the V100 is 1.73x. Overcoming bandwidth limits is a common challenge for GPU application developers.\n  Shared Memory, L1 Cache Size, and Registers: Since memory bandwidth limits GPU performance, an efficient memory hierarchy is required to transfer data faster to the Tensor cores. The Ampere architecture optimizes the available memory bandwidth by implementing an improved memory hierarchy, from global memory to shared memory tiles, and finally to register tiles for Tensor Cores. In this way, the data transfer to and from the Tensor Cores is more efficient, allowing them to be utilized more effectively. Therefore, shared memory, L1 cache size, and registers are critical components in optimizing memory hierarchy and achieving maximum performance in Deep Learning workloads. A generic diagram of GPU memory hierarchy is as follows    We can see that the bandwidth amplifies as we move to left side, to the computing cores. Cache hierarchy reduces throughput demand on main memory  Process of running a program on a GPU Prior 2007 (GPU) If the task was to draw a picture using a GPU, the process would have been as follows:\n The application, through the graphics driver, provided the GPU with vertex and fragment shader program binaries. The application set graphics pipeline parameters, such as output image size. The application provided the GPU with a buffer of vertices. The GPU executed drawPrimitives(vertex_buffer) to render the image.  However, early GPU hardware could only execute graphics pipeline computations.\nAfter 2007 (GP-GPU) If the task was to run a computational workload on the GPU, the process would be as follows:\n The application allocated buffers in the GPU memory. The data was copied to and from the buffers. The application, through the graphics driver, provided the GPU with a single kernel program binary. The application instructed the GPU to run the kernel in a single program multiple data (SPMD) fashion by specifying the number of instances to run. The GPU launched the kernel using launch(myKernel, N).  Comparison: CPU vs GPU Now we know about CPU and GPU hardware components. Let us do a quick comparison for both.\nCharacteristics of CPUs:  ALUs  CPUs have fewer (typically up to 40) but more complex cores compared to GPUs. These cores are designed to handle a variety of tasks, rather than specialized graphics processing.   Control Units (CU)  CPUs typically have a large number of control units. These control units are responsible for managing and executing a wide range of tasks, such as running the operating system and multiple applications simultaneously.   Cache  CPUs have large caches, typically measured in megabytes. The cache is a high-speed memory that allows the processor to access frequently-used data quickly, improving performance. If the required data is not in the cache, it can take much longer (around 100 clock cycles) to retrieve it from memory. Large caches help to minimize latency and optimize performance.   Clock Speed  CPUs typically have high clock speeds, measured in gigahertz (GHz). This is because CPUs are designed to handle a wide range of tasks, and their computations are typically single-threaded. Higher clock speeds can improve single-thread performance.   RAM  CPUs typically have access to a large amount of RAM, often measured in terabytes. RAM is a type of temporary storage that allows data to be accessed quickly, enabling many programs to be run simultaneously.    Characteristics of GPU:  ALUs  Large number of cores (e.g., 6912 tensor cores for A100) GPUs are designed to perform the same computation on multiple data items in parallel, which enables them to process vast amounts of data in a single workload. Compute units are based on SIMD hardware.   Control Units  Small number of units GPUs often perform similar tasks repeatedly (e.g., computing matrices or modeling complex numbers), so they do not require a large number of control units.   Cache  Small cache size (in KBs) GPUs prioritize computation power over cache, and therefore do not need a large cache.   Clock speed  Slower clock speed (in MHz) GPUs perform the same set of operations on data repeatedly, and therefore do not need a high clock speed.   VRAM (Video RAM), device memory  Large capacity (in GBs) Used to exchange data between the CPU and GPU Allocated and managed by the CPU Accessible to both the CPU and GPU Significantly larger than L1 and L2 cache registers Requires high bandwidth to facilitate data exchange between the CPU and GPU.    Quick summary: GPU vs CPU CPU and GPU have different strengths and weaknesses. CPUs have very large main memory (RAM), fast clock speeds, and latency optimized via large caches. However, they have relatively low memory bandwidth and cache misses are very costly. In addition, CPUs have low performance/watt and low per thread performance each core runs at ~1 Ghz, which is 4 times slower than a GPU core.\nOn the other hand, GPUs have high bandwidth main memory, more compute resources (cores), and high throughput. They use data parallelism where the same instruction is applied to different data. However, GPUs have relatively low memory capacity, small caches, and run at slower clock speeds (MHz).\nIn summary, CPUs are designed for low latency and low throughput tasks, while GPUs are designed for high latency and high throughput tasks. CPUs use task parallelism, where multiple tasks map to multiple threads, while GPUs use data parallelism, where the same instruction is applied to different data.\nWhich GPUs to choose for Deep Learning? I will cover this question in another detailed post, right now lets discuss briefly the facotrs to consider when choosing GPUs for ML Workloads. These factors are as follows:\n Tensor cores (explained previously) Memory bandwidth  If we take the Tesla A100 GPU bandwidth vs Tesla V100 bandwidth, we get a speedup of 1555/900 = 1.73x   Shared memory size  For example, We have the following shared memory sizes on the following architectures: Volta: 96kb shared memory / 32 kb L1 Turing: 64kb shared memory / 32 kb L1 Ampere: 164 kb shared memory / 32 kb L1    Summary In this post, we explored GPUs in-depth and gained a good understanding of their hardware architecture and the key differences between GPUs and CPUs. We also discussed the technical specifications that are important to consider when purchasing a GPU for machine learning workloads, such as tensor cores, memory bandwidth, and shared memory size. Additionally, we briefly touched on how to choose a GPU specifically for deep learning. In future posts, we will cover this topic in more detail.\nReferences  https://download.nvidia.com/developer/cuda/seminar/TDCI_Arch.pdf https://www.cs.cmu.edu/afs/cs/academic/class/15418-s18/www/lectures/06_gpuarch.pd http://haifux.org/lectures/267/Introduction-to-GPUs.pdf https://ec.europa.eu/programmes/erasmus-plus/project-result-content/52dfac24-28e9-4379-8f28-f8ed05e225e0/lec03_gpu_architectures.pdf https://download.nvidia.com/developer/cuda/seminar/TDCI_Arch.pdf https://hdms.bsz-bw.de/frontdoor/deliver/index/docId/4500/file/gpgpu-origins-and-gpu-hardware-architecture.pdf https://www.cs.cmu.edu/afs/cs/academic/class/15418-s18/www/lectures/06_gpuarch.pdf http://www.irisa.fr/alf/downloads/collange/cours/ada2020_gpu_1.pdf https://homes.luddy.indiana.edu/achauhan/Teaching/B649/2011-Fall/StudentPresns/gpu-arch.pdf http://www.ziti.uni-heidelberg.de/ziti/uploads/ce_group/seminar/2014-Daniel_Schlegel-presentation.pdf https://www.control.lth.se/fileadmin/control/Education/DoctorateProgram/DeepLearning/2016/presentation.pdf https://www.nvidia.co.uk/docs/IO/147844/Deep-Learning-With-GPUs-MaximMilakov-NVIDIA.pdf https://repository.library.northeastern.edu/files/neu:m046sc381/fulltext.pdf https://www.comp.nus.edu.sg/~cs2100/2_resources/AppendixA_Graphics_and_Computing_GPUs.pdf http://www.compsci.hunter.cuny.edu/~sweiss/course_materials/csci360/lecture_notes/gpus.pdf https://www.cs.wm.edu/~kemper/cs654/slides/nvidia.pdf http://passlab.github.io/CSE436536/notes/lecture19_GPUArchCUDA01.pdf https://www.cs.utah.edu/~jeffp/teaching/MCMD/S20-GPU.pdf http://courses.cms.caltech.edu/cs101gpu/Old/2015_lectures/cs179_2015_lec05.pdf http://haifux.org/lectures/267/Introduction-to-GPUs.pdf https://www.nvidia.com/en-us/geforce/graphics-cards/compare/ https://blog.paperspace.com/gpu-memory-bandwidth/ https://www.cs.cmu.edu/afs/cs/academic/class/15418-s18/www/lectures/06_gpuarch.pdf  ","wordCount":"2294","inLanguage":"en","datePublished":"2022-12-26T11:00:00+05:00","dateModified":"2022-12-26T11:00:00+05:00","author":{"@type":"Person","name":"Umer Jamil"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://umerjamil16.github.io/posts/guide-gpu-ml/"},"publisher":{"@type":"Organization","name":"Umer Jamil ","logo":{"@type":"ImageObject","url":"https://umerjamil16.github.io/%3Clink%20/%20abs%20url%3E"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://umerjamil16.github.io/ accesskey=h title="Home (Alt + H)">
<img src=https://umerjamil16.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a>
<div class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</div>
</div>
<ul id=menu>
<li>
<a href=https://umerjamil16.github.io/categories/ title=categories>
<span>categories</span>
</a>
</li>
<li>
<a href=https://umerjamil16.github.io/tags/ title=tags>
<span>tags</span>
</a>
</li>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<div class=breadcrumbs><a href=https://umerjamil16.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://umerjamil16.github.io/posts/>Posts</a></div>
<h1 class=post-title>
A Beginner's Guide to GPUs for Machine Learning Workloads
</h1>
<div class=post-meta><span title="2022-12-26 11:00:00 +0500 +0500">December 26, 2022</span>&nbsp;·&nbsp;11 min&nbsp;·&nbsp;2294 words&nbsp;·&nbsp;Umer Jamil&nbsp;|&nbsp;<a href=#/posts/guide-gpu-ml.md rel="noopener noreferrer" target=_blank>Suggest Changes (Disabled)</a>
</div>
</header>
<div class=post-content><p><img loading=lazy src=https://static.techspot.com/articles-info/2486/images/2022-06-21-image-16-j_1100.webp alt="GPU picture ">
</p>
<p>This blog aims to provide a basic understanding of GPUs for ML/MLOps Engineers, without going into extensive technical details. The focus will be on developing a broad knowledge of GPUs to aid in hardware decision-making for managing ML/DL workloads and pipelines. This blog will not include comparisons of different GPU architectures for ML workloads.</p>
<p>Before we begin, let&rsquo;s review some key terminologies that will be used throughout this blog:</p>
<ul>
<li>Latency: The time delay between the initiation of a task and the detection of its effects.</li>
<li>Throughput: The amount of work completed within a given timeframe.</li>
<li>FLOPS: Floating-Point Operations Per Second, used to measure the computing performance of the ALUs.</li>
<li>Device: A GPU consisting of multiple multiprocessors.</li>
<li>Device memory: The VRAM of a GPU.</li>
<li>Host: The CPU of the system on which the GPU is installed.</li>
<li>Multiprocessor: A set of processors and shared memory within a GPU.</li>
<li>Kernel: A GPU program used to execute tasks (not to be confused with the Linux kernel).</li>
<li>SIMD: Single Instruction, Multiple Data units, which perform the same operation on multiple data operands simultaneously and are commonly found in GPUs.</li>
<li>GP-GPUs: General-Purpose Graphics Processing Units, which can be used for a range of tasks beyond graphics processing.</li>
<li>CUDA: Compute Unified Device Architecture, a programming model and parallel computing platform for general computing on GPUs.</li>
<li>ALUs: Arithmetic Logic Units, which carry out arithmetic and logic operations on the operands in computer instruction words.</li>
<li>Cache: A smaller, faster memory located closer to a processor core that stores copies of frequently used data from main memory locations.</li>
<li>Registers: Small amounts of data, computer instructions, or storage addresses that hold information.</li>
<li>Clock speed: The number of cycles that the processor executes per second.</li>
</ul>
<h2 id=what-is-a-gpu>What is a GPU<a hidden class=anchor aria-hidden=true href=#what-is-a-gpu>#</a></h2>
<p>A GPU, or Graphics Processing Unit, was originally designed to handle specific graphics pipeline operations and real-time rendering. However, GPUs have since evolved into highly efficient general-purpose hardware with massive computing power. This has led to their increased usage in machine learning and other data-intensive applications.</p>
<p>The initial GPUs were designed with fixed functions to handle specific pipeline stages, as shown in the following diagram:
<img loading=lazy src=https://i.postimg.cc/zv30c7yQ/gpu1.png alt="GPU Architecture">
</p>
<p>A simplified architecture of early GPUs is shown below:<img loading=lazy src=https://i.postimg.cc/RCjDYrTQ/gpu2.png alt="GPU Architecture">
</p>
<p>Each fixed function the GPU performed had dedicated API calls that were implemented in hardware. To use GPUs for computational workloads, tasks had to be mapped to the computer graphics domain. Early GPUs used graphics languages like OpenGL, but this approach was not scalable for problem domains that didn&rsquo;t map well to computer graphics.</p>
<p>This led to the development of general-purpose GPU (GP-GPU) architectures and corresponding programming models like CUDA, CAL, and OpenCL. Modern GP-GPUs have high FLOPS, with the NVIDIA A100 delivering up to 312 teraFLOPS. They also offer programmability, unlike early GPUs which were focused on integer arithmetic and lacked instruction sets and memory for high throughput.</p>
<p>GP-GPUs are programmable processors, and they have memory and instruction sets designed to handle high throughput of floating-point arithmetic operations. They are highly parallelizable, with thousands of cores per device that are organized into multiprocessors. Each multiprocessor consists of multiple processors and shared memory. A kernel is a GPU program that is executed by a multiprocessor.</p>
<p>GP-GPUs use Single Instruction, Multiple Data (SIMD) units to perform the same operation on multiple data operands concurrently. They also have caches and registers to hold frequently used data or instructions, which reduces memory latency.</p>
<p>Overall, GP-GPUs have evolved from their initial purpose of handling graphics pipeline operations to become powerful hardware for data-intensive applications. Their massive computing power and programmability make them a valuable tool for ML/MLOps engineers managing ML/DL workloads and pipelines.</p>
<h2 id=hardware-components>Hardware Components<a hidden class=anchor aria-hidden=true href=#hardware-components>#</a></h2>
<p>To understand the hardware components of GPUs, we need to understand the hardware components of the CPU first.</p>
<h3 id=cpu-hardware>CPU Hardware<a hidden class=anchor aria-hidden=true href=#cpu-hardware>#</a></h3>
<p>A Central Processing Unit (CPU) is the primary component of a computer system that executes instructions of a program.
<img loading=lazy src=https://i.postimg.cc/tCJFF76B/1-sh8h-Dj-O4x0-S0-Q-JGx-GTKc-Q.png alt="CPU Architecture">
</p>
<p>It has the following components:</p>
<ol>
<li>
<p>Arithmetic Logic Unit (ALU): The ALU performs the arithmetic and logical functions of a CPU. It is responsible for performing calculations such as addition, subtraction, and comparison operations.</p>
</li>
<li>
<p>Registers: Registers are used to store data temporarily during and after operations. They are used to facilitate data movement between different components of the CPU.</p>
</li>
<li>
<p>Control Units: Control units are responsible for managing the execution of instructions. They decide which instruction to execute and then which data to pick up and send to the ALU for execution.</p>
</li>
<li>
<p>Cache: The CPU uses cache memory to store frequently accessed data and instructions closer to the processing unit. The cache memory is faster than the main system memory (RAM) and is designed to predict what data and program instructions will be needed next. The cache memory hierarchy includes L1, L2, and L3 caches, where L1 is closest to the CPU and is used for storing the microprocessor&rsquo;s recently accessed information.</p>
</li>
<li>
<p>RAM: Random Access Memory (RAM) is a temporary storage bank used to store data so that it can be retrieved quickly. When a program is loaded into RAM, the CPU reads instructions and data from RAM and then processes them.</p>
</li>
</ol>
<h4 id=process-of-running-a-program-on-a-multicore-cpu>Process of running a program on a multicore CPU<a hidden class=anchor aria-hidden=true href=#process-of-running-a-program-on-a-multicore-cpu>#</a></h4>
<p>The process of running a program on a multicore CPU involves the operating system (OS) loading the program into RAM, selecting the CPU execution context, and preparing the execution context (i.e., setting the contents of registers, program counter, etc.) before starting the trigger to execute instructions.</p>
<p>Now we understand what is a CPU and how it works, let us dive into the difference between CPU and GPU</p>
<h3 id=gpu-hardware>GPU Hardware<a hidden class=anchor aria-hidden=true href=#gpu-hardware>#</a></h3>
<p>A Graphics Processing Unit (GPU) is a specialized processor designed to handle the computational requirements of graphics and other highly parallelizable tasks. A cartoon diagram of Nvidai GPU is shown below:
<img loading=lazy src=https://i.postimg.cc/PfRCsyLM/gpu3.png alt="GPU nvidia architecture">
</p>
<p>The three main components of GPUs are:</p>
<ol>
<li>
<p>ALUs and Tensor Cores:
In NVIDIA GPUs, ALUs are the smallest units of processing that are grouped into cores. For example, each CUDA core in the A100 GPU consists of 32 ALUs, and there are 6912 CUDA cores in total. Additionally, NVIDIA has introduced Tensor cores in their latest Ampere architecture, which are specialized processing units that are particularly well-suited for Deep Learning workloads involving large matrix multiplications. Tensor cores can perform multiple operations per clock cycle, which is significantly faster than the one-operation-per-clock cycle performed by CUDA cores. With Tensor cores, computation is no longer the bottleneck; instead, the primary bottleneck is the speed at which data can be transferred to and from memory (Memory Bandwidth). Therefore, for Deep Learning workloads, it is preferable to have a GPU with Tensor cores.</p>
</li>
<li>
<p>Memory Bandwidth:
Memory bandwidth is an often-overlooked metric in GPUs but is critical for performance. It refers to how quickly data can be moved between the memory (VRAM) and computation cores. If a GPU has poor memory bandwidth but excellent computation cores, the computation cores will be underutilized due to slower data transfer speeds. For instance, during the training of the BERT Large model, Tensor core utilization was only around 30%, meaning that Tensor cores sat idle for 70% of the time due to data availability delays. GPU memory bandwidth is the best indicator of performance, with the A100 GPU having 1,555 GB/s memory bandwidth compared to the V100&rsquo;s 900 GB/s. Thus, a basic estimate of the A100&rsquo;s speedup over the V100 is 1.73x. Overcoming bandwidth limits is a common challenge for GPU application developers.</p>
</li>
<li>
<p>Shared Memory, L1 Cache Size, and Registers:
Since memory bandwidth limits GPU performance, an efficient memory hierarchy is required to transfer data faster to the Tensor cores. The Ampere architecture optimizes the available memory bandwidth by implementing an improved memory hierarchy, from global memory to shared memory tiles, and finally to register tiles for Tensor Cores. In this way, the data transfer to and from the Tensor Cores is more efficient, allowing them to be utilized more effectively. Therefore, shared memory, L1 cache size, and registers are critical components in optimizing memory hierarchy and achieving maximum performance in Deep Learning workloads.
A generic diagram of GPU memory hierarchy is as follows
<img loading=lazy src=https://i.postimg.cc/BZgdX75x/gpu4.png alt="GPU Memory Hierarchy">
</p>
</li>
</ol>
<ul>
<li>We can see that the bandwidth amplifies as we move to left side, to the computing cores. Cache hierarchy reduces throughput demand on main memory</li>
</ul>
<h4 id=process-of-running-a-program-on-a-gpu>Process of running a program on a GPU<a hidden class=anchor aria-hidden=true href=#process-of-running-a-program-on-a-gpu>#</a></h4>
<h5 id=prior-2007-gpu>Prior 2007 (GPU)<a hidden class=anchor aria-hidden=true href=#prior-2007-gpu>#</a></h5>
<p>If the task was to draw a picture using a GPU, the process would have been as follows:</p>
<ol>
<li>The application, through the graphics driver, provided the GPU with vertex and fragment shader program binaries.</li>
<li>The application set graphics pipeline parameters, such as output image size.</li>
<li>The application provided the GPU with a buffer of vertices.</li>
<li>The GPU executed drawPrimitives(vertex_buffer) to render the image.</li>
</ol>
<p>However, early GPU hardware could only execute graphics pipeline computations.</p>
<h5 id=after-2007-gp-gpu>After 2007 (GP-GPU)<a hidden class=anchor aria-hidden=true href=#after-2007-gp-gpu>#</a></h5>
<p>If the task was to run a computational workload on the GPU, the process would be as follows:</p>
<ol>
<li>The application allocated buffers in the GPU memory.</li>
<li>The data was copied to and from the buffers.</li>
<li>The application, through the graphics driver, provided the GPU with a single kernel program binary.</li>
<li>The application instructed the GPU to run the kernel in a single program multiple data (SPMD) fashion by specifying the number of instances to run.</li>
<li>The GPU launched the kernel using launch(myKernel, N).</li>
</ol>
<h2 id=comparison-cpu-vs-gpu>Comparison: CPU vs GPU<a hidden class=anchor aria-hidden=true href=#comparison-cpu-vs-gpu>#</a></h2>
<p>Now we know about CPU and GPU hardware components. Let us do a quick comparison for both.</p>
<h3 id=characteristics-of-cpus>Characteristics of CPUs:<a hidden class=anchor aria-hidden=true href=#characteristics-of-cpus>#</a></h3>
<ol>
<li>ALUs
<ul>
<li>CPUs have fewer (typically up to 40) but more complex cores compared to GPUs.</li>
<li>These cores are designed to handle a variety of tasks, rather than specialized graphics processing.</li>
</ul>
</li>
<li>Control Units (CU)
<ul>
<li>CPUs typically have a large number of control units.</li>
<li>These control units are responsible for managing and executing a wide range of tasks, such as running the operating system and multiple applications simultaneously.</li>
</ul>
</li>
<li>Cache
<ul>
<li>CPUs have large caches, typically measured in megabytes.</li>
<li>The cache is a high-speed memory that allows the processor to access frequently-used data quickly, improving performance.</li>
<li>If the required data is not in the cache, it can take much longer (around 100 clock cycles) to retrieve it from memory.</li>
<li>Large caches help to minimize latency and optimize performance.</li>
</ul>
</li>
<li>Clock Speed
<ul>
<li>CPUs typically have high clock speeds, measured in gigahertz (GHz).</li>
<li>This is because CPUs are designed to handle a wide range of tasks, and their computations are typically single-threaded.</li>
<li>Higher clock speeds can improve single-thread performance.</li>
</ul>
</li>
<li>RAM
<ul>
<li>CPUs typically have access to a large amount of RAM, often measured in terabytes.</li>
<li>RAM is a type of temporary storage that allows data to be accessed quickly, enabling many programs to be run simultaneously.</li>
</ul>
</li>
</ol>
<h3 id=characteristics-of-gpu>Characteristics of GPU:<a hidden class=anchor aria-hidden=true href=#characteristics-of-gpu>#</a></h3>
<ol>
<li>ALUs
<ul>
<li>Large number of cores (e.g., 6912 tensor cores for A100)</li>
<li>GPUs are designed to perform the same computation on multiple data items in parallel, which enables them to process vast amounts of data in a single workload.</li>
<li>Compute units are based on SIMD hardware.</li>
</ul>
</li>
<li>Control Units
<ul>
<li>Small number of units</li>
<li>GPUs often perform similar tasks repeatedly (e.g., computing matrices or modeling complex numbers), so they do not require a large number of control units.</li>
</ul>
</li>
<li>Cache
<ul>
<li>Small cache size (in KBs)</li>
<li>GPUs prioritize computation power over cache, and therefore do not need a large cache.</li>
</ul>
</li>
<li>Clock speed
<ul>
<li>Slower clock speed (in MHz)</li>
<li>GPUs perform the same set of operations on data repeatedly, and therefore do not need a high clock speed.</li>
</ul>
</li>
<li>VRAM (Video RAM), device memory
<ul>
<li>Large capacity (in GBs)</li>
<li>Used to exchange data between the CPU and GPU</li>
<li>Allocated and managed by the CPU</li>
<li>Accessible to both the CPU and GPU</li>
<li>Significantly larger than L1 and L2 cache registers</li>
<li>Requires high bandwidth to facilitate data exchange between the CPU and GPU.</li>
</ul>
</li>
</ol>
<h3 id=quick-summary-gpu-vs-cpu>Quick summary: GPU vs CPU<a hidden class=anchor aria-hidden=true href=#quick-summary-gpu-vs-cpu>#</a></h3>
<p>CPU and GPU have different strengths and weaknesses. CPUs have very large main memory (RAM), fast clock speeds, and latency optimized via large caches. However, they have relatively low memory bandwidth and cache misses are very costly. In addition, CPUs have low performance/watt and low per thread performance each core runs at ~1 Ghz, which is 4 times slower than a GPU core.</p>
<p>On the other hand, GPUs have high bandwidth main memory, more compute resources (cores), and high throughput. They use data parallelism where the same instruction is applied to different data. However, GPUs have relatively low memory capacity, small caches, and run at slower clock speeds (MHz).</p>
<p>In summary, CPUs are designed for low latency and low throughput tasks, while GPUs are designed for high latency and high throughput tasks. CPUs use task parallelism, where multiple tasks map to multiple threads, while GPUs use data parallelism, where the same instruction is applied to different data.</p>
<h2 id=which-gpus-to-choose-for-deep-learning>Which GPUs to choose for Deep Learning?<a hidden class=anchor aria-hidden=true href=#which-gpus-to-choose-for-deep-learning>#</a></h2>
<p>I will cover this question in another detailed post, right now lets discuss briefly the facotrs to consider when choosing GPUs for ML Workloads. These factors are as follows:</p>
<ol>
<li>Tensor cores (explained previously)</li>
<li>Memory bandwidth
<ul>
<li>If we take the Tesla A100 GPU bandwidth vs Tesla V100 bandwidth, we get a speedup of 1555/900 = 1.73x</li>
</ul>
</li>
<li>Shared memory size
<ul>
<li>For example, We have the following shared memory sizes on the following architectures:</li>
<li>Volta: 96kb shared memory / 32 kb L1</li>
<li>Turing: 64kb shared memory / 32 kb L1</li>
<li>Ampere: 164 kb shared memory / 32 kb L1</li>
</ul>
</li>
</ol>
<h2 id=summary>Summary<a hidden class=anchor aria-hidden=true href=#summary>#</a></h2>
<p>In this post, we explored GPUs in-depth and gained a good understanding of their hardware architecture and the key differences between GPUs and CPUs. We also discussed the technical specifications that are important to consider when purchasing a GPU for machine learning workloads, such as tensor cores, memory bandwidth, and shared memory size. Additionally, we briefly touched on how to choose a GPU specifically for deep learning. In future posts, we will cover this topic in more detail.</p>
<h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2>
<ol>
<li><a href=https://download.nvidia.com/developer/cuda/seminar/TDCI_Arch.pdf>https://download.nvidia.com/developer/cuda/seminar/TDCI_Arch.pdf</a></li>
<li><a href=https://www.cs.cmu.edu/afs/cs/academic/class/15418-s18/www/lectures/06_gpuarch.pdf>https://www.cs.cmu.edu/afs/cs/academic/class/15418-s18/www/lectures/06_gpuarch.pd</a></li>
<li><a href=http://haifux.org/lectures/267/Introduction-to-GPUs.pdf>http://haifux.org/lectures/267/Introduction-to-GPUs.pdf</a></li>
<li><a href=https://ec.europa.eu/programmes/erasmus-plus/project-result-content/52dfac24-28e9-4379-8f28-f8ed05e225e0/lec03_gpu_architectures.pdf>https://ec.europa.eu/programmes/erasmus-plus/project-result-content/52dfac24-28e9-4379-8f28-f8ed05e225e0/lec03_gpu_architectures.pdf</a></li>
<li><a href=https://download.nvidia.com/developer/cuda/seminar/TDCI_Arch.pdf>https://download.nvidia.com/developer/cuda/seminar/TDCI_Arch.pdf</a></li>
<li><a href=https://hdms.bsz-bw.de/frontdoor/deliver/index/docId/4500/file/gpgpu-origins-and-gpu-hardware-architecture.pdf>https://hdms.bsz-bw.de/frontdoor/deliver/index/docId/4500/file/gpgpu-origins-and-gpu-hardware-architecture.pdf</a></li>
<li><a href=https://www.cs.cmu.edu/afs/cs/academic/class/15418-s18/www/lectures/06_gpuarch.pdf>https://www.cs.cmu.edu/afs/cs/academic/class/15418-s18/www/lectures/06_gpuarch.pdf</a></li>
<li><a href=http://www.irisa.fr/alf/downloads/collange/cours/ada2020_gpu_1.pdf>http://www.irisa.fr/alf/downloads/collange/cours/ada2020_gpu_1.pdf</a></li>
<li><a href=https://homes.luddy.indiana.edu/achauhan/Teaching/B649/2011-Fall/StudentPresns/gpu-arch.pdf>https://homes.luddy.indiana.edu/achauhan/Teaching/B649/2011-Fall/StudentPresns/gpu-arch.pdf</a></li>
<li><a href=http://www.ziti.uni-heidelberg.de/ziti/uploads/ce_group/seminar/2014-Daniel_Schlegel-presentation.pdf>http://www.ziti.uni-heidelberg.de/ziti/uploads/ce_group/seminar/2014-Daniel_Schlegel-presentation.pdf</a></li>
<li><a href=https://www.control.lth.se/fileadmin/control/Education/DoctorateProgram/DeepLearning/2016/presentation.pdf>https://www.control.lth.se/fileadmin/control/Education/DoctorateProgram/DeepLearning/2016/presentation.pdf</a></li>
<li><a href=https://www.nvidia.co.uk/docs/IO/147844/Deep-Learning-With-GPUs-MaximMilakov-NVIDIA.pdf>https://www.nvidia.co.uk/docs/IO/147844/Deep-Learning-With-GPUs-MaximMilakov-NVIDIA.pdf</a></li>
<li><a href=https://repository.library.northeastern.edu/files/neu:m046sc381/fulltext.pdf>https://repository.library.northeastern.edu/files/neu:m046sc381/fulltext.pdf</a></li>
<li><a href=https://www.comp.nus.edu.sg/~cs2100/2_resources/AppendixA_Graphics_and_Computing_GPUs.pdf>https://www.comp.nus.edu.sg/~cs2100/2_resources/AppendixA_Graphics_and_Computing_GPUs.pdf</a></li>
<li><a href=http://www.compsci.hunter.cuny.edu/~sweiss/course_materials/csci360/lecture_notes/gpus.pdf>http://www.compsci.hunter.cuny.edu/~sweiss/course_materials/csci360/lecture_notes/gpus.pdf</a></li>
<li><a href=https://www.cs.wm.edu/~kemper/cs654/slides/nvidia.pdf>https://www.cs.wm.edu/~kemper/cs654/slides/nvidia.pdf</a></li>
<li><a href=http://passlab.github.io/CSE436536/notes/lecture19_GPUArchCUDA01.pdf>http://passlab.github.io/CSE436536/notes/lecture19_GPUArchCUDA01.pdf</a></li>
<li><a href=https://www.cs.utah.edu/~jeffp/teaching/MCMD/S20-GPU.pdf>https://www.cs.utah.edu/~jeffp/teaching/MCMD/S20-GPU.pdf</a></li>
<li><a href=http://courses.cms.caltech.edu/cs101gpu/Old/2015_lectures/cs179_2015_lec05.pdf>http://courses.cms.caltech.edu/cs101gpu/Old/2015_lectures/cs179_2015_lec05.pdf</a></li>
<li><a href=http://haifux.org/lectures/267/Introduction-to-GPUs.pdf>http://haifux.org/lectures/267/Introduction-to-GPUs.pdf</a></li>
<li><a href=https://www.nvidia.com/en-us/geforce/graphics-cards/compare/>https://www.nvidia.com/en-us/geforce/graphics-cards/compare/</a></li>
<li><a href=https://blog.paperspace.com/gpu-memory-bandwidth/>https://blog.paperspace.com/gpu-memory-bandwidth/</a></li>
<li><a href=https://www.cs.cmu.edu/afs/cs/academic/class/15418-s18/www/lectures/06_gpuarch.pdf>https://www.cs.cmu.edu/afs/cs/academic/class/15418-s18/www/lectures/06_gpuarch.pdf</a></li>
</ol>
</div>
<footer class=post-footer>
<ul class=post-tags>
<li><a href=https://umerjamil16.github.io/tags/mlops/>MLOps</a></li>
<li><a href=https://umerjamil16.github.io/tags/devops/>DevOps</a></li>
<li><a href=https://umerjamil16.github.io/tags/nvidia/>Nvidia</a></li>
<li><a href=https://umerjamil16.github.io/tags/gpu/>GPU</a></li>
<li><a href=https://umerjamil16.github.io/tags/operations/>Operations</a></li>
<li><a href=https://umerjamil16.github.io/tags/gpus/>GPUs</a></li>
<li><a href=https://umerjamil16.github.io/tags/machine-learning/>Machine Learning</a></li>
<li><a href=https://umerjamil16.github.io/tags/deep-learning/>Deep Learning</a></li>
<li><a href=https://umerjamil16.github.io/tags/hardware/>Hardware</a></li>
<li><a href=https://umerjamil16.github.io/tags/computer-architecture/>Computer Architecture</a></li>
<li><a href=https://umerjamil16.github.io/tags/technical-specifications/>Technical Specifications</a></li>
<li><a href=https://umerjamil16.github.io/tags/performance/>Performance</a></li>
<li><a href=https://umerjamil16.github.io/tags/data-processing/>Data Processing</a></li>
<li><a href=https://umerjamil16.github.io/tags/data-parallelism/>Data Parallelism</a></li>
<li><a href=https://umerjamil16.github.io/tags/task-parallelism/>Task Parallelism</a></li>
<li><a href=https://umerjamil16.github.io/tags/memory-bandwidth/>Memory Bandwidth</a></li>
<li><a href=https://umerjamil16.github.io/tags/shared-memory/>Shared Memory</a></li>
<li><a href=https://umerjamil16.github.io/tags/tensor-cores/>Tensor Cores</a></li>
<li><a href=https://umerjamil16.github.io/tags/deep-learning-workloads/>Deep Learning Workloads</a></li>
</ul>
<nav class=paginav>
<a class=prev href=https://umerjamil16.github.io/posts/consistency-strategic-adv/>
<span class=title>« Prev</span>
<br>
<span>Consistency as a Strategic Advantage</span>
</a>
<a class=next href=https://umerjamil16.github.io/posts/kaldi_docker/>
<span class=title>Next »</span>
<br>
<span>Containerizing Kaldi - the speech recognition toolkit</span>
</a>
</nav>
<div class=share-buttons>
<a target=_blank rel="noopener noreferrer" aria-label="share A Beginner's Guide to GPUs for Machine Learning Workloads on twitter" href="https://twitter.com/intent/tweet/?text=A%20Beginner%27s%20Guide%20to%20GPUs%20for%20Machine%20Learning%20Workloads&url=https%3a%2f%2fumerjamil16.github.io%2fposts%2fguide-gpu-ml%2f&hashtags=MLOps%2cDevOps%2cNvidia%2cGPU%2cOperations%2cGPUs%2cMachineLearning%2cDeepLearning%2cHardware%2cComputerArchitecture%2cTechnicalSpecifications%2cPerformance%2cDataProcessing%2cDataParallelism%2cTaskParallelism%2cMemoryBandwidth%2cSharedMemory%2cTensorCores%2cDeepLearningWorkloads"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share A Beginner's Guide to GPUs for Machine Learning Workloads on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fumerjamil16.github.io%2fposts%2fguide-gpu-ml%2f&title=A%20Beginner%27s%20Guide%20to%20GPUs%20for%20Machine%20Learning%20Workloads&summary=A%20Beginner%27s%20Guide%20to%20GPUs%20for%20Machine%20Learning%20Workloads&source=https%3a%2f%2fumerjamil16.github.io%2fposts%2fguide-gpu-ml%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share A Beginner's Guide to GPUs for Machine Learning Workloads on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fumerjamil16.github.io%2fposts%2fguide-gpu-ml%2f&title=A%20Beginner%27s%20Guide%20to%20GPUs%20for%20Machine%20Learning%20Workloads"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share A Beginner's Guide to GPUs for Machine Learning Workloads on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fumerjamil16.github.io%2fposts%2fguide-gpu-ml%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share A Beginner's Guide to GPUs for Machine Learning Workloads on whatsapp" href="https://api.whatsapp.com/send?text=A%20Beginner%27s%20Guide%20to%20GPUs%20for%20Machine%20Learning%20Workloads%20-%20https%3a%2f%2fumerjamil16.github.io%2fposts%2fguide-gpu-ml%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share A Beginner's Guide to GPUs for Machine Learning Workloads on telegram" href="https://telegram.me/share/url?text=A%20Beginner%27s%20Guide%20to%20GPUs%20for%20Machine%20Learning%20Workloads&url=https%3a%2f%2fumerjamil16.github.io%2fposts%2fguide-gpu-ml%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg>
</a>
</div>
</footer>
</article>
</main>
<footer class=footer>
<span>&copy; 2024 <a href=https://umerjamil16.github.io/>Umer Jamil </a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
</body>
</html>