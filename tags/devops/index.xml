<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DevOps on Umer Jamil </title>
    <link>https://umerjamil16.github.io/tags/devops/</link>
    <description>Recent content in DevOps on Umer Jamil </description>
    <image>
      <url>https://umerjamil16.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://umerjamil16.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Mon, 26 Dec 2022 11:00:00 +0500</lastBuildDate><atom:link href="https://umerjamil16.github.io/tags/devops/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>A Beginner&#39;s Guide to GPUs for Machine Learning Workloads</title>
      <link>https://umerjamil16.github.io/posts/guide-gpu-ml/</link>
      <pubDate>Mon, 26 Dec 2022 11:00:00 +0500</pubDate>
      
      <guid>https://umerjamil16.github.io/posts/guide-gpu-ml/</guid>
      <description>This blog aims to provide a basic understanding of GPUs for ML/MLOps Engineers, without going into extensive technical details. The focus will be on developing a broad knowledge of GPUs to aid in hardware decision-making for managing ML/DL workloads and pipelines. This blog will not include comparisons of different GPU architectures for ML workloads.
Before we begin, let&amp;rsquo;s review some key terminologies that will be used throughout this blog:
 Latency: The time delay between the initiation of a task and the detection of its effects.</description>
    </item>
    
    <item>
      <title>Developing a reasonable understanding of GPUs for ML Workloads</title>
      <link>https://umerjamil16.github.io/posts/gpus-1/</link>
      <pubDate>Mon, 26 Dec 2022 11:00:00 +0500</pubDate>
      
      <guid>https://umerjamil16.github.io/posts/gpus-1/</guid>
      <description>This blog is intended to develop a “breadth” level understanding of GPUs, and not a “depth” level. My aim will be to build a “reasonable” understanding that will help in our hardware decision-making for managing ML/DL workloads and pipelines from the perspective of an ML/MLOps Engineer. This blog does not contain comparisons of different GPU architectures for ML workloads.
Before diving, let&amp;rsquo;s quickly recap some key terminologies which will be used in upcoming paras.</description>
    </item>
    
    <item>
      <title>Containerizing Kaldi - the speech recognition toolkit</title>
      <link>https://umerjamil16.github.io/posts/kaldi_docker/</link>
      <pubDate>Tue, 29 Nov 2022 11:00:00 +0500</pubDate>
      
      <guid>https://umerjamil16.github.io/posts/kaldi_docker/</guid>
      <description>Kaldi is a very popular Automatic Speech Recognition (ASR) toolkit. In my experience, setting up Kaldi on a system can take huge amount of time. Therefore, it is best to use containerization approach.
Following is the Dockerfile that I wrote. We will be using a cuda enabled Ubuntu 18.04 image from Nvidia NGC:
FROM nvidia/cuda:11.1.1-cudnn8-devel-ubuntu18.04 LABEL Author=&amp;#34;umerjamil16@github.io&amp;#34; Email=&amp;#34;umer1694@gmail.com&amp;#34; LABEL Description=&amp;#34;Kaldi ASR Image&amp;#34; Vendor=&amp;#34;x&amp;#34; Version=&amp;#34;1.0&amp;#34; RUN sh -c &amp;#39;echo &amp;#34;APT { Get { AllowUnauthenticated \&amp;#34;1\&amp;#34;; }; };&amp;#34; &amp;gt; /etc/apt/apt.</description>
    </item>
    
    <item>
      <title>Introduction to DevOps</title>
      <link>https://umerjamil16.github.io/posts/devops-intro/</link>
      <pubDate>Mon, 28 Nov 2022 11:00:00 +0500</pubDate>
      
      <guid>https://umerjamil16.github.io/posts/devops-intro/</guid>
      <description>DevOps is the evolution of software development lifecycle. Last week, at Rayn, I gave a talk on DevOps, the process, the methodology, and how adopting DevOps methodology can help IT and business teams. The presentation content is as follows:
Thank you for for your time. Hope you liked the content.</description>
    </item>
    
  </channel>
</rss>
